{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#importing the libraries\nimport warnings\nwarnings.filterwarnings('ignore')\nimport numpy as np\nimport pandas as pd","execution_count":82,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#loading the data\ntrain_data = pd.read_csv('../input/health-insurance-lead-prediction/train_Df64byy.csv').drop('ID', axis = 1)\ntest_data = pd.read_csv('../input/health-insurance-lead-prediction/test_YCcRUnU.csv').drop('ID', axis = 1)","execution_count":83,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":84,"outputs":[{"output_type":"execute_result","execution_count":84,"data":{"text/plain":"  City_Code  Region_Code Accomodation_Type Reco_Insurance_Type  Upper_Age  \\\n0        C3         3213            Rented          Individual         36   \n1        C5         1117             Owned               Joint         75   \n2        C5         3732             Owned          Individual         32   \n3       C24         4378             Owned               Joint         52   \n4        C8         2190            Rented          Individual         44   \n\n   Lower_Age Is_Spouse Health Indicator Holding_Policy_Duration  \\\n0         36        No               X1                     14+   \n1         22        No               X2                     NaN   \n2         32        No              NaN                     1.0   \n3         48        No               X1                     14+   \n4         44        No               X2                     3.0   \n\n   Holding_Policy_Type  Reco_Policy_Cat  Reco_Policy_Premium  Response  \n0                  3.0               22              11628.0         0  \n1                  NaN               22              30510.0         0  \n2                  1.0               19               7450.0         1  \n3                  3.0               19              17780.0         0  \n4                  1.0               16              10404.0         0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>City_Code</th>\n      <th>Region_Code</th>\n      <th>Accomodation_Type</th>\n      <th>Reco_Insurance_Type</th>\n      <th>Upper_Age</th>\n      <th>Lower_Age</th>\n      <th>Is_Spouse</th>\n      <th>Health Indicator</th>\n      <th>Holding_Policy_Duration</th>\n      <th>Holding_Policy_Type</th>\n      <th>Reco_Policy_Cat</th>\n      <th>Reco_Policy_Premium</th>\n      <th>Response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>C3</td>\n      <td>3213</td>\n      <td>Rented</td>\n      <td>Individual</td>\n      <td>36</td>\n      <td>36</td>\n      <td>No</td>\n      <td>X1</td>\n      <td>14+</td>\n      <td>3.0</td>\n      <td>22</td>\n      <td>11628.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>C5</td>\n      <td>1117</td>\n      <td>Owned</td>\n      <td>Joint</td>\n      <td>75</td>\n      <td>22</td>\n      <td>No</td>\n      <td>X2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>22</td>\n      <td>30510.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>C5</td>\n      <td>3732</td>\n      <td>Owned</td>\n      <td>Individual</td>\n      <td>32</td>\n      <td>32</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>19</td>\n      <td>7450.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>C24</td>\n      <td>4378</td>\n      <td>Owned</td>\n      <td>Joint</td>\n      <td>52</td>\n      <td>48</td>\n      <td>No</td>\n      <td>X1</td>\n      <td>14+</td>\n      <td>3.0</td>\n      <td>19</td>\n      <td>17780.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>C8</td>\n      <td>2190</td>\n      <td>Rented</td>\n      <td>Individual</td>\n      <td>44</td>\n      <td>44</td>\n      <td>No</td>\n      <td>X2</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>16</td>\n      <td>10404.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# exploring the target column\nprint(train_data.Response.describe())\nprint('-'*30)\nprint(train_data.Response.value_counts())","execution_count":85,"outputs":[{"output_type":"stream","text":"count    50882.000000\nmean         0.239947\nstd          0.427055\nmin          0.000000\n25%          0.000000\n50%          0.000000\n75%          0.000000\nmax          1.000000\nName: Response, dtype: float64\n------------------------------\n0    38673\n1    12209\nName: Response, dtype: int64\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding out the columns with null values\ntrain_data.isna().sum()","execution_count":86,"outputs":[{"output_type":"execute_result","execution_count":86,"data":{"text/plain":"City_Code                      0\nRegion_Code                    0\nAccomodation_Type              0\nReco_Insurance_Type            0\nUpper_Age                      0\nLower_Age                      0\nIs_Spouse                      0\nHealth Indicator           11691\nHolding_Policy_Duration    20251\nHolding_Policy_Type        20251\nReco_Policy_Cat                0\nReco_Policy_Premium            0\nResponse                       0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data type of variables\ntrain_data.dtypes","execution_count":87,"outputs":[{"output_type":"execute_result","execution_count":87,"data":{"text/plain":"City_Code                   object\nRegion_Code                  int64\nAccomodation_Type           object\nReco_Insurance_Type         object\nUpper_Age                    int64\nLower_Age                    int64\nIs_Spouse                   object\nHealth Indicator            object\nHolding_Policy_Duration     object\nHolding_Policy_Type        float64\nReco_Policy_Cat              int64\nReco_Policy_Premium        float64\nResponse                     int64\ndtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all the columns\ntrain_data.columns","execution_count":88,"outputs":[{"output_type":"execute_result","execution_count":88,"data":{"text/plain":"Index(['City_Code', 'Region_Code', 'Accomodation_Type', 'Reco_Insurance_Type',\n       'Upper_Age', 'Lower_Age', 'Is_Spouse', 'Health Indicator',\n       'Holding_Policy_Duration', 'Holding_Policy_Type', 'Reco_Policy_Cat',\n       'Reco_Policy_Premium', 'Response'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making a list of columns which have categories in their values\ncols = ['City_Code','Region_Code','Accomodation_Type', 'Reco_Insurance_Type','Holding_Policy_Type',\n        'Reco_Policy_Cat','Health Indicator']","execution_count":89,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let us explore the Region_Code variable\nregion_count = train_data['Region_Code'].value_counts()\nprint(len(region_count[region_count<10]))\nprint(len(region_count[region_count>10]))","execution_count":103,"outputs":[{"output_type":"stream","text":"3165\n1928\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"We see that  there are many categories which have less that ten value counts, so we decide to replace them all with 'OTHERS'"},{"metadata":{"trusted":true},"cell_type":"code","source":"replace_these = list(region_count[region_count<10].index)\ntrain_data['Region_Code'] = train_data['Region_Code'].replace(replace_these,'OTHERS')","execution_count":104,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we do same with the test_data "},{"metadata":{"trusted":true},"cell_type":"code","source":"region_count = test_data['Region_Code'].value_counts()\nreplace_these = list(region_count[region_count<10].index)\ntest_data['Region_Code'] = test_data['Region_Code'].replace(replace_these,'OTHERS')","execution_count":105,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Now we fill the NaN values\n* And create a dummies columns for all categorical columns, I am not using here the get_dummies finction because it is not guaranteed to have same categories in training and testing in realistic dataset, that's why I create a set containing the common categories between test and train dataset; and then create the encoding for only them "},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in cols:\n    train_data[col] = train_data[col].fillna('UA')\n    test_data[col] = test_data[col].fillna('UA')\n    uniques = list(set(list(train_data[col].unique())).intersection(set(list(test_data[col].unique()))))\n    for unique in uniques:\n        train_data['Is_'+col+'_equal_'+str(unique)] = train_data[col].apply(lambda x: (x==unique)*1.0)\n        test_data['Is_'+col+'_equal_'+str(unique)] = test_data[col].apply(lambda x: (x==unique)*1.0) \n    train_data = train_data.drop(col,axis = 1)\n    test_data = test_data.drop(col,axis = 1)","execution_count":106,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let us see the columns list"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data.columns)","execution_count":107,"outputs":[{"output_type":"stream","text":"Index(['Upper_Age', 'Lower_Age', 'Is_Spouse', 'Holding_Policy_Duration',\n       'Reco_Policy_Premium', 'Response', 'Is_City_Code_equal_C34',\n       'Is_City_Code_equal_C29', 'Is_City_Code_equal_C36',\n       'Is_City_Code_equal_C12',\n       ...\n       'Is_Health Indicator_equal_X2', 'Is_Health Indicator_equal_X7',\n       'Is_Health Indicator_equal_X3', 'Is_Health Indicator_equal_X9',\n       'Is_Health Indicator_equal_X6', 'Is_Health Indicator_equal_X4',\n       'Is_Health Indicator_equal_X1', 'Is_Health Indicator_equal_UA',\n       'Is_Health Indicator_equal_X8', 'Is_Health Indicator_equal_X5'],\n      dtype='object', length=527)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"So we have 527 columns, Now let us do some feature engineering"},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"def yes_no(x):\n    if x== 'Yes': return 1\n    return 0\n\ndef digited(x):\n    dicts = {'1.0':1, '14.0':14,'3.0':3,'7.0':7, \n             '0.0':0, '2.0':2, '11.0':11,'6.0':6, \n             '4.0':4,'8.0':8, '9.0':9, '10.0':10, \n             '5.0':5, '12.0':12, '13.0':13}\n    return dicts[x]\n\ndef divider(x,y):\n    if y==0: return 0\n    return x/y\n\ndef extreme_z(x):\n    if x< -1.5: \n        return 1\n    elif x>4:\n        return 1\n    else:\n        return 0","execution_count":109,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# function for creating new features\ndef feature_addition(data):\n    data['Holding_Policy_Duration'] = data['Holding_Policy_Duration'].fillna('0.0')\n    data['Holding_Policy_Duration_more_than_14'] = data['Holding_Policy_Duration'].apply(lambda x: x=='14+')\n    data['Holding_Policy_Duration'] = data['Holding_Policy_Duration'].replace('14+','14.0')\n    data['Holding_Policy_Duration'] = data['Holding_Policy_Duration'].apply(lambda x: digited(x))\n    data['Is_Spouse'] = data['Is_Spouse'].apply(lambda x: yes_no(x))\n    data['Age_difference'] = data['Upper_Age'] - data['Lower_Age']\n    data['Is_Age_difference_0'] = data['Age_difference'].apply(lambda x: x==0)\n    data['policy_duration_difference_ratio'] = data.apply(lambda x: divider(x['Age_difference'],x['Holding_Policy_Duration']),axis = 1)\n    data['Reco_Policy_Premium_z'] = data['Reco_Policy_Premium'].apply(lambda x: (x/6500 - 2))\n    data['Reco_Policy_extreme'] = data['Reco_Policy_Premium_z'].apply(extreme_z)\n    return data","execution_count":111,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making new features on train as well as test data\ntrain_data = feature_addition(train_data)\ntest_data = feature_addition(test_data)","execution_count":112,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# defining independent and target varible \nX = train_data.drop('Response',axis = 1)\nY = train_data['Response']","execution_count":59,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"###  Train Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.model_selection import train_test_split as tts\nX_train,X_test,Y_train,Y_test = tts(X,Y,test_size = 0.2,random_state = 42,\n                                    stratify = Y)","execution_count":60,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let us make the model with limited parameter and run it on the train data\nI am using xgboost fpr the final model because it gave maximum score in comparison to  others\nAlso I am using scale_pos_weight = 4 in the parameter because the data is imbalanced and the ration of both the classes count is almost 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import classification_report\n\nclassifier = XGBClassifier(\n                            eval_metric = 'error',\n                            scale_pos_weight = 4)\n\nclassifier.fit(X_train,Y_train)\nY_pred_train = classifier.predict(X_train)\nY_pred_test = classifier.predict(X_test)\nprint(classification_report(Y_train,Y_pred_train))\nprint(classification_report(Y_test,Y_pred_test))\nprint(roc_auc_score(Y_train,Y_pred_train))\nprint(roc_auc_score(Y_test,Y_pred_test))","execution_count":113,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.94      0.45      0.61     30938\n           1       0.34      0.91      0.50      9767\n\n    accuracy                           0.56     40705\n   macro avg       0.64      0.68      0.55     40705\nweighted avg       0.80      0.56      0.58     40705\n\n              precision    recall  f1-score   support\n\n           0       0.87      0.41      0.56      7735\n           1       0.30      0.81      0.44      2442\n\n    accuracy                           0.51     10177\n   macro avg       0.59      0.61      0.50     10177\nweighted avg       0.74      0.51      0.53     10177\n\n0.6808732698720977\n0.6102101925631337\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"As we have see the roc_auc score on the train data, let us make prediction for test data and create a submission file"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_pred=classifier.predict(test_data)\ndf_sub=pd.DataFrame(submission_pred,columns=['Response'])\ndf_sub.insert(loc=0, column='ID', value=df_sub.index+50883)\ndf_sub.to_csv('xgboost.csv', index=False)","execution_count":114,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}